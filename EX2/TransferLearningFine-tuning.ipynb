{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision as tv\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "num_workers = 0\n",
    "# how many samples per batch to load\n",
    "batch_size = 20\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    " ])  \n",
    "\n",
    "trainset = tv.datasets.MNIST(root='./data',  train=True, download=True, transform=transform)\n",
    "testset  = tv.datasets.MNIST(root='./data',  train=False, download=True, transform=transform)\n",
    "train_loader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True, num_workers=num_workers)\n",
    "test_loader = torch.utils.data.DataLoader(testset, batch_size=batch_size, shuffle=True, num_workers=num_workers)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ConvAutoencoder(\n",
      "  (encoder): Encoder(\n",
      "    (conv1): Conv2d(1, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (conv2): Conv2d(16, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (fc): Linear(in_features=196, out_features=12, bias=True)\n",
      "  )\n",
      "  (decoder): Decoder(\n",
      "    (fc): Linear(in_features=12, out_features=196, bias=True)\n",
      "    (t_conv1): ConvTranspose2d(4, 16, kernel_size=(2, 2), stride=(2, 2))\n",
      "    (t_conv2): ConvTranspose2d(16, 1, kernel_size=(2, 2), stride=(2, 2))\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Encoder, self).__init__()\n",
    "        # conv layer (depth from 1 --> 16), 3x3 kernels\n",
    "        self.conv1 = nn.Conv2d(1, 16, 3, padding=1)  \n",
    "        # conv layer (depth from 16 --> 4), 3x3 kernels\n",
    "        self.conv2 = nn.Conv2d(16, 4, 3, padding=1)\n",
    "        # pooling layer to reduce x-y dims by two; kernel and stride of 2\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.fc = nn.Linear(4 * 7 * 7, 12)  # FC layer to latent space\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = self.pool(x)\n",
    "        # add second hidden layer\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = self.pool(x)  # compressed representation\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.fc = nn.Linear(12, 4 * 7 * 7)  # FC layer from latent space\n",
    "        self.t_conv1 = nn.ConvTranspose2d(4, 16, 2, stride=2)\n",
    "        self.t_conv2 = nn.ConvTranspose2d(16, 1, 2, stride=2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc(x)\n",
    "        x = x.view(x.size(0), 4, 7, 7)\n",
    "        x = F.relu(self.t_conv1(x))\n",
    "        # output layer (with sigmoid for scaling from 0 to 1)\n",
    "        x = F.sigmoid(self.t_conv2(x))\n",
    "        return x\n",
    "\n",
    "class ConvAutoencoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvAutoencoder, self).__init__()\n",
    "        self.encoder = Encoder()\n",
    "        self.decoder = Decoder()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.decoder(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "# initialize the NN\n",
    "model = ConvAutoencoder().to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 \tTraining Loss: 2.237107\n",
      "Epoch: 2 \tTraining Loss: 1.806833\n",
      "Epoch: 3 \tTraining Loss: 1.641887\n",
      "Epoch: 4 \tTraining Loss: 1.453331\n",
      "Epoch: 5 \tTraining Loss: 1.283768\n",
      "Epoch: 6 \tTraining Loss: 1.170697\n",
      "Epoch: 7 \tTraining Loss: 1.138093\n",
      "Epoch: 8 \tTraining Loss: 1.117833\n",
      "Epoch: 9 \tTraining Loss: 1.104474\n",
      "Epoch: 10 \tTraining Loss: 1.096116\n",
      "Epoch: 11 \tTraining Loss: 1.089944\n",
      "Epoch: 12 \tTraining Loss: 1.084892\n",
      "Epoch: 13 \tTraining Loss: 1.080035\n",
      "Epoch: 14 \tTraining Loss: 1.075264\n",
      "Epoch: 15 \tTraining Loss: 1.071525\n",
      "Epoch: 16 \tTraining Loss: 1.068036\n",
      "Epoch: 17 \tTraining Loss: 1.064893\n",
      "Epoch: 18 \tTraining Loss: 1.061259\n",
      "Epoch: 19 \tTraining Loss: 1.057897\n",
      "Epoch: 20 \tTraining Loss: 1.054829\n"
     ]
    }
   ],
   "source": [
    "# specify loss function\n",
    "criterion = nn.L1Loss()\n",
    "\n",
    "# specify loss function\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "n_epochs = 20\n",
    "\n",
    "for epoch in range(1, n_epochs+1):\n",
    "    # monitor training loss\n",
    "    train_loss = 0.0\n",
    "    \n",
    "    ###################\n",
    "    # train the model #\n",
    "    ###################\n",
    "    for data in train_loader:\n",
    "        # _ stands in for labels, here\n",
    "        # no need to flatten images\n",
    "        images, _ = data\n",
    "        images = images.to(device)\n",
    "        # clear the gradients of all optimized variables\n",
    "        optimizer.zero_grad()\n",
    "        # forward pass: compute predicted outputs by passing inputs to the model\n",
    "        outputs = model(images)\n",
    "        # calculate the loss\n",
    "        loss = criterion(outputs, images)\n",
    "        # backward pass: compute gradient of the loss with respect to model parameters\n",
    "        loss.backward()\n",
    "        # perform a single optimization step (parameter update)\n",
    "        optimizer.step()\n",
    "        # update running training loss\n",
    "        train_loss += loss.item()*images.size(0)\n",
    "            \n",
    "    # print avg training statistics \n",
    "    train_loss = train_loss/len(train_loader)\n",
    "    print('Epoch: {} \\tTraining Loss: {:.6f}'.format(\n",
    "        epoch, \n",
    "        train_loss\n",
    "        ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision as tv\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "import torch.utils.data as data_utils\n",
    "\n",
    "num_workers = 0\n",
    "# how many samples per batch to load\n",
    "batch_size = 20\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    " ])  \n",
    "\n",
    "trainset = tv.datasets.MNIST(root='./data',  train=True, download=True, transform=transform)\n",
    "testset  = tv.datasets.MNIST(root='./data',  train=False, download=True, transform=transform)\n",
    "\n",
    "\n",
    "indices = torch.arange(100)\n",
    "train_loader_CLS = data_utils.Subset(trainset, indices)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_loader_CLS, batch_size=batch_size,shuffle=True, num_workers=0)\n",
    "test_loader = torch.utils.data.DataLoader(testset, batch_size=batch_size, shuffle=True, num_workers=num_workers)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransferClassifierEncoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(TransferClassifierEncoder, self).__init__()\n",
    "        self.encoder = model.encoder\n",
    "        self.fc1 = nn.Linear(12, 16)\n",
    "        self.fc2 = nn.Linear(16, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "    \n",
    "\n",
    "transfer_model = TransferClassifierEncoder().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in model.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/20], Train Loss: 4.3498, Train Accuracy: 14.00%, Test Loss: 3.3430, Test Accuracy: 21.73%\n",
      "Epoch [2/20], Train Loss: 2.1741, Train Accuracy: 31.00%, Test Loss: 2.1228, Test Accuracy: 42.34%\n",
      "Epoch [3/20], Train Loss: 1.1950, Train Accuracy: 61.00%, Test Loss: 1.5475, Test Accuracy: 56.14%\n",
      "Epoch [4/20], Train Loss: 0.8800, Train Accuracy: 72.00%, Test Loss: 1.2917, Test Accuracy: 64.50%\n",
      "Epoch [5/20], Train Loss: 0.6209, Train Accuracy: 87.00%, Test Loss: 1.3050, Test Accuracy: 65.29%\n",
      "Epoch [6/20], Train Loss: 0.4833, Train Accuracy: 87.00%, Test Loss: 1.1910, Test Accuracy: 67.14%\n",
      "Epoch [7/20], Train Loss: 0.3772, Train Accuracy: 92.00%, Test Loss: 1.0794, Test Accuracy: 69.04%\n",
      "Epoch [8/20], Train Loss: 0.3015, Train Accuracy: 94.00%, Test Loss: 0.9870, Test Accuracy: 71.55%\n",
      "Epoch [9/20], Train Loss: 0.2553, Train Accuracy: 94.00%, Test Loss: 0.9644, Test Accuracy: 72.07%\n",
      "Epoch [10/20], Train Loss: 0.2114, Train Accuracy: 93.00%, Test Loss: 0.9445, Test Accuracy: 72.73%\n",
      "Epoch [11/20], Train Loss: 0.1759, Train Accuracy: 97.00%, Test Loss: 0.9613, Test Accuracy: 72.73%\n",
      "Epoch [12/20], Train Loss: 0.1584, Train Accuracy: 97.00%, Test Loss: 0.9700, Test Accuracy: 72.99%\n",
      "Epoch [13/20], Train Loss: 0.1370, Train Accuracy: 96.00%, Test Loss: 0.9847, Test Accuracy: 73.70%\n",
      "Epoch [14/20], Train Loss: 0.1263, Train Accuracy: 98.00%, Test Loss: 0.9987, Test Accuracy: 73.91%\n",
      "Epoch [15/20], Train Loss: 0.1192, Train Accuracy: 98.00%, Test Loss: 1.0192, Test Accuracy: 73.53%\n",
      "Epoch [16/20], Train Loss: 0.1073, Train Accuracy: 96.00%, Test Loss: 1.0209, Test Accuracy: 74.37%\n",
      "Epoch [17/20], Train Loss: 0.0862, Train Accuracy: 98.00%, Test Loss: 1.0529, Test Accuracy: 74.11%\n",
      "Epoch [18/20], Train Loss: 0.0830, Train Accuracy: 98.00%, Test Loss: 1.1101, Test Accuracy: 73.35%\n",
      "Epoch [19/20], Train Loss: 0.0742, Train Accuracy: 98.00%, Test Loss: 1.1435, Test Accuracy: 73.91%\n",
      "Epoch [20/20], Train Loss: 0.0717, Train Accuracy: 98.00%, Test Loss: 1.1637, Test Accuracy: 73.82%\n"
     ]
    }
   ],
   "source": [
    "# specify loss function\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# specify loss function\n",
    "optimizer = torch.optim.Adam(transfer_model.parameters(), lr=0.01)\n",
    "\n",
    "n_epochs = 20\n",
    "\n",
    "train_losses = []\n",
    "test_losses = []\n",
    "train_accuracies = []\n",
    "test_accuracies = []\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    transfer_model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = transfer_model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "    train_losses.append(running_loss / len(train_loader))\n",
    "    train_accuracies.append(100 * correct / total)\n",
    "\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = transfer_model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            running_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    test_losses.append(running_loss / len(test_loader))\n",
    "    test_accuracies.append(100 * correct / total)\n",
    "\n",
    "    print(f'Epoch [{epoch+1}/{n_epochs}], Train Loss: {train_losses[-1]:.4f}, Train Accuracy: {train_accuracies[-1]:.2f}%, Test Loss: {test_losses[-1]:.4f}, Test Accuracy: {test_accuracies[-1]:.2f}%')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
